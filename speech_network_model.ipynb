{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing the Speech Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Modules for Building the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 1: GeForce GTX 980 Ti (CNMeM is enabled with initial size: 40.0% of memory, CuDNN 4007)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "import ctc_cost\n",
    "import h5py\n",
    "import random\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initial parameters\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS=1\n",
    "VALIDATION_SIZE=0.2\n",
    "\n",
    "batch_size=125\n",
    "feature_size=55\n",
    "frames=336\n",
    "num_phonomes=62"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Bidirectional LSTM Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Rebuilding the DBRNN\n",
    "#Source: http://www.cs.toronto.edu/~graves/asru_2013.pdf\n",
    "\n",
    "#input layer\n",
    "input_layer=lasagne.layers.InputLayer(shape=(batch_size, frames, feature_size))\n",
    "batchsize, fm, feature = input_layer.input_var.shape\n",
    "\n",
    "\n",
    "#layer 1\n",
    "fwd_layer_1=lasagne.layers.LSTMLayer(input_layer,num_units=256, backwards=False, learn_init=True)\n",
    "bwd_layer_1=lasagne.layers.LSTMLayer(input_layer, num_units=256, backwards=True, learn_init=True)\n",
    "recurrent_layer_1= lasagne.layers.ElemwiseSumLayer([fwd_layer_1,bwd_layer_1])\n",
    "\n",
    "#layer 2\n",
    "fwd_layer_2=lasagne.layers.LSTMLayer(recurrent_layer_1,num_units=256, backwards=False, learn_init=True)\n",
    "bwd_layer_2=lasagne.layers.LSTMLayer(recurrent_layer_1, num_units=256, backwards=True, learn_init=True)\n",
    "recurrent_layer_2= lasagne.layers.ElemwiseSumLayer([fwd_layer_2,bwd_layer_2])\n",
    "\n",
    "#layer 3\n",
    "fwd_layer_3=lasagne.layers.LSTMLayer(recurrent_layer_2,num_units=256, backwards=False, learn_init=True)\n",
    "bwd_layer_3=lasagne.layers.LSTMLayer(recurrent_layer_2, num_units=256, backwards=True, learn_init=True)\n",
    "recurrent_layer_3= lasagne.layers.ElemwiseSumLayer([fwd_layer_3,bwd_layer_3])\n",
    "\n",
    "#layer 4\n",
    "fwd_layer_4=lasagne.layers.LSTMLayer(recurrent_layer_3,num_units=256, backwards=False, learn_init=True)\n",
    "bwd_layer_4=lasagne.layers.LSTMLayer(recurrent_layer_3, num_units=256, backwards=True, learn_init=True)\n",
    "recurrent_layer_4= lasagne.layers.ElemwiseSumLayer([fwd_layer_4,bwd_layer_4])\n",
    "\n",
    "#layer 5\n",
    "fwd_layer_5=lasagne.layers.LSTMLayer(recurrent_layer_4,num_units=256, backwards=False, learn_init=True)\n",
    "bwd_layer_5=lasagne.layers.LSTMLayer(recurrent_layer_4, num_units=256, backwards=True, learn_init=True)\n",
    "recurrent_layer_5= lasagne.layers.ElemwiseSumLayer([fwd_layer_5,bwd_layer_5])\n",
    "\n",
    "#connected layers\n",
    "reshape_layer=lasagne.layers.ReshapeLayer(recurrent_layer_5,(-1,256))\n",
    "densed_output_layer=lasagne.layers.DenseLayer(reshape_layer, num_units=num_phonomes, nonlinearity=lasagne.nonlinearities.identity)\n",
    "output_reshape=lasagne.layers.ReshapeLayer(densed_output_layer, (batchsize, fm, num_phonomes))\n",
    "\n",
    "#softmax of the connected layer\n",
    "output_softmax=lasagne.layers.NonlinearityLayer(densed_output_layer, nonlinearity=lasagne.nonlinearities.softmax)\n",
    "output_softmax_shp=lasagne.layers.ReshapeLayer(output_softmax, (batchsize, fm, num_phonomes))\n",
    "\n",
    "output_lin_ctc=lasagne.layers.get_output(output_reshape)\n",
    "network_output=lasagne.layers.get_output(output_softmax_shp)\n",
    "all_params=lasagne.layers.get_all_params(recurrent_layer_5, trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Costs and Training Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing updates ...\n",
      "Compiling functions ...\n"
     ]
    }
   ],
   "source": [
    "# Cost functions\n",
    "target_values = T.imatrix('target_output')\n",
    "input_values  = T.imatrix()\n",
    "\n",
    "### Gradients ###\n",
    "# pseudo costs - ctc cross entropy b/n targets and linear output - used in training\n",
    "pseudo_cost = ctc_cost.pseudo_cost(target_values, output_lin_ctc)\n",
    "pseudo_cost_grad = T.grad(pseudo_cost.sum() / batchsize, all_params)\n",
    "pseudo_cost = pseudo_cost.mean()\n",
    "\n",
    "# true costs\n",
    "cost = ctc_cost.cost(target_values, network_output)\n",
    "cost = cost.mean()\n",
    "\n",
    "# Compute SGD updates for training\n",
    "print(\"Computing updates ...\")\n",
    "updates = lasagne.updates.rmsprop(pseudo_cost_grad, all_params, LEARNING_RATE)\n",
    "\n",
    "# Theano functions for training and computing cost\n",
    "print(\"Compiling functions ...\")\n",
    "train = theano.function([input_layer.input_var, target_values], [cost, pseudo_cost, network_output], updates=updates)\n",
    "validate = theano.function([input_layer.input_var, target_values], [cost, network_output]) \n",
    "predict  = theano.function([input_layer.input_var], network_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data in Batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Training Audio File Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_frame_size=0\n",
    "audio_names=[]\n",
    "\n",
    "\n",
    "with h5py.File('timit_files/train_audio.h5', 'r') as h5:\n",
    "    with open('audio_key.txt','r') as f:\n",
    "        for line in f:\n",
    "            line=line.rstrip()\n",
    "            audio_names.append(line)\n",
    "            cur=h5[line].shape[1]\n",
    "            #print cur\n",
    "            if cur>max_frame_size:\n",
    "                max_frame_size=cur\n",
    "number_of_audio_files=len(audio_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#transposing the data and creating a 3d tensor\n",
    "all_audio=np.zeros((number_of_audio_files,336,55))\n",
    "file_ind=0\n",
    "with open('audio_key.txt','r') as f:\n",
    "    for line in f:\n",
    "        line=line.rstrip()\n",
    "        with h5py.File('timit_files/train_audio_zero_padded.h5', 'r') as h5:\n",
    "            zero_padded_audio=np.transpose(h5[line][:])\n",
    "            for i in range(zero_padded_audio.shape[0]):\n",
    "                for j in range(zero_padded_audio.shape[1]):\n",
    "                    all_audio[file_ind][i][j]=zero_padded_audio[i][j]\n",
    "            file_ind+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_phn=np.zeros((number_of_audio_files,151))\n",
    "file_ind=0\n",
    "with open('audio_key.txt','r') as f:\n",
    "    for line in f:\n",
    "        line=line.rstrip()\n",
    "        with h5py.File('timit_files/phoneme_list_encode_space_padded.h5', 'r') as h5:\n",
    "            blank_padded_phn=h5[line][:]\n",
    "            for i in range(blank_padded_phn.shape[0]):\n",
    "                all_phn[file_ind][i]=blank_padded_phn[i]\n",
    "            file_ind+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#combining all the data as one\n",
    "all_audio=all_audio.astype(np.float32)\n",
    "all_phn=all_phn.astype(np.int32)\n",
    "training_data=zip(all_audio,all_phn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training network ...\n",
      "EPOCH #0\n",
      "Batch 0/36, loss:1153.8, ploss:5.3493\n",
      "Batch 1/36, loss:216.18, ploss:-548.2\n",
      "Batch 2/36, loss:212.86, ploss:429.48\n",
      "Batch 3/36, loss:222.15, ploss:-529.0\n",
      "Batch 4/36, loss:150.04, ploss:355.24\n",
      "Batch 5/36, loss:42.538, ploss:44.621\n",
      "Batch 6/36, loss:83.971, ploss:-135.1\n",
      "Batch 7/36, loss:84.363, ploss:243.67\n",
      "Batch 8/36, loss:42.048, ploss:-100.1\n",
      "Batch 9/36, loss:28.336, ploss:95.203\n",
      "Batch 10/36, loss:33.233, ploss:-113.0\n",
      "Batch 11/36, loss:30.251, ploss:122.78\n",
      "Batch 12/36, loss:23.965, ploss:-74.49\n",
      "Batch 13/36, loss:16.484, ploss:52.102\n",
      "Batch 14/36, loss:16.608, ploss:-61.75\n",
      "Batch 15/36, loss:19.096, ploss:60.873\n",
      "Batch 16/36, loss:15.813, ploss:-89.53\n",
      "Batch 17/36, loss:19.165, ploss:87.715\n",
      "Batch 18/36, loss:14.848, ploss:-91.60\n",
      "Batch 19/36, loss:18.361, ploss:87.599\n",
      "Batch 20/36, loss:8.5992, ploss:-77.33\n",
      "Batch 21/36, loss:14.297, ploss:66.326\n",
      "Batch 22/36, loss:7.6399, ploss:-66.27\n",
      "Batch 23/36, loss:7.7050, ploss:54.274\n",
      "Batch 24/36, loss:7.9469, ploss:-60.07\n",
      "Batch 25/36, loss:3.6586, ploss:58.587\n",
      "Batch 26/36, loss:9.2555, ploss:-73.30\n",
      "Batch 27/36, loss:12.822, ploss:86.842\n",
      "Batch 28/36, loss:3.6713, ploss:-76.49\n",
      "Batch 29/36, loss:16.232, ploss:75.206\n",
      "Batch 30/36, loss:8.0851, ploss:-70.58\n",
      "Batch 31/36, loss:5.6586, ploss:61.753\n",
      "Batch 32/36, loss:5.8813, ploss:-57.71\n",
      "Batch 33/36, loss:8.2865, ploss:53.569\n",
      "Batch 34/36, loss:5.7756, ploss:-63.64\n",
      "Batch 35/36, loss:9.5141, ploss:70.256\n",
      "EPOCH #1\n",
      "Batch 0/36, loss:3.3915, ploss:-72.62\n",
      "Batch 1/36, loss:10.592, ploss:77.061\n",
      "Batch 2/36, loss:5.0234, ploss:-77.34\n",
      "Batch 3/36, loss:9.1165, ploss:73.791\n",
      "Batch 4/36, loss:13.601, ploss:-79.00\n",
      "Batch 5/36, loss:9.1849, ploss:85.389\n",
      "Batch 6/36, loss:4.5024, ploss:-54.28\n",
      "Batch 7/36, loss:-0.532, ploss:36.452\n",
      "Batch 8/36, loss:-1.823, ploss:-35.62\n",
      "Batch 9/36, loss:8.6803, ploss:24.851\n",
      "Batch 10/36, loss:1.4138, ploss:-48.60\n",
      "Batch 11/36, loss:-0.696, ploss:52.503\n",
      "Batch 12/36, loss:1.9775, ploss:-62.34\n",
      "Batch 13/36, loss:2.5189, ploss:68.387\n",
      "Batch 14/36, loss:3.3136, ploss:-57.25\n",
      "Batch 15/36, loss:0.8869, ploss:43.168\n",
      "Batch 16/36, loss:0.7015, ploss:-66.97\n",
      "Batch 17/36, loss:5.8020, ploss:84.211\n",
      "Batch 18/36, loss:11.954, ploss:-117.1\n",
      "Batch 19/36, loss:13.364, ploss:102.13\n",
      "Batch 20/36, loss:1.0866, ploss:-68.14\n",
      "Batch 21/36, loss:10.342, ploss:69.179\n",
      "Batch 22/36, loss:1.4431, ploss:-50.21\n",
      "Batch 23/36, loss:6.2659, ploss:34.991\n",
      "Batch 24/36, loss:-3.762, ploss:-30.75\n",
      "Batch 25/36, loss:5.7588, ploss:10.716\n",
      "Batch 26/36, loss:1.5945, ploss:-16.16\n",
      "Batch 27/36, loss:-3.212, ploss:5.6730\n",
      "Batch 28/36, loss:-2.646, ploss:-15.95\n",
      "Batch 29/36, loss:-11.42, ploss:4.7293\n",
      "Batch 30/36, loss:-6.908, ploss:-23.59\n",
      "Batch 31/36, loss:-1.386, ploss:16.838\n",
      "Batch 32/36, loss:-5.371, ploss:-44.49\n",
      "Batch 33/36, loss:-1.399, ploss:69.711\n",
      "Batch 34/36, loss:-3.358, ploss:-84.37\n",
      "Batch 35/36, loss:5.6328, ploss:116.86\n",
      "EPOCH #2\n",
      "Batch 0/36, loss:0.5604, ploss:-68.62\n",
      "Batch 1/36, loss:-7.346, ploss:71.547\n",
      "Batch 2/36, loss:1.0997, ploss:-63.29\n",
      "Batch 3/36, loss:0.2054, ploss:55.092\n",
      "Batch 4/36, loss:-7.122, ploss:-35.37\n",
      "Batch 5/36, loss:-15.18, ploss:12.256\n",
      "Batch 6/36, loss:-2.410, ploss:-21.45\n",
      "Batch 7/36, loss:-6.140, ploss:-0.442\n",
      "Batch 8/36, loss:-2.537, ploss:-15.36\n",
      "Batch 9/36, loss:-0.687, ploss:6.9574\n",
      "Batch 10/36, loss:-5.547, ploss:-29.18\n",
      "Batch 11/36, loss:-10.36, ploss:26.921\n",
      "Batch 12/36, loss:-21.28, ploss:-43.66\n",
      "Batch 13/36, loss:-11.30, ploss:44.754\n",
      "Batch 14/36, loss:-5.596, ploss:-68.53\n",
      "Batch 15/36, loss:-5.401, ploss:62.655\n",
      "Batch 16/36, loss:4.8223, ploss:-69.27\n",
      "Batch 17/36, loss:-5.252, ploss:73.354\n",
      "Batch 18/36, loss:0.1362, ploss:-50.37\n",
      "Batch 19/36, loss:-6.614, ploss:55.174\n",
      "Batch 20/36, loss:-8.544, ploss:-49.14\n",
      "Batch 21/36, loss:-13.87, ploss:30.167\n",
      "Batch 22/36, loss:-6.925, ploss:-38.12\n",
      "Batch 23/36, loss:-7.448, ploss:18.473\n",
      "Batch 24/36, loss:-16.43, ploss:-25.13\n",
      "Batch 25/36, loss:-11.20, ploss:-0.222\n",
      "Batch 26/36, loss:-8.619, ploss:-8.965\n",
      "Batch 27/36, loss:-8.202, ploss:-12.90\n",
      "Batch 28/36, loss:-18.54, ploss:-1.113\n",
      "Batch 29/36, loss:-8.524, ploss:-24.68\n",
      "Batch 30/36, loss:-16.92, ploss:13.682\n",
      "Batch 31/36, loss:-11.34, ploss:-42.53\n",
      "Batch 32/36, loss:-6.153, ploss:41.157\n",
      "Batch 33/36, loss:-16.66, ploss:-67.72\n",
      "Batch 34/36, loss:-11.66, ploss:70.609\n",
      "Batch 35/36, loss:-12.62, ploss:-80.20\n",
      "EPOCH #3\n",
      "Batch 0/36, loss:-0.591, ploss:87.492\n",
      "Batch 1/36, loss:-17.81, ploss:-44.97\n",
      "Batch 2/36, loss:-12.48, ploss:22.335\n",
      "Batch 3/36, loss:-21.14, ploss:-37.60\n",
      "Batch 4/36, loss:-23.24, ploss:3.0879\n",
      "Batch 5/36, loss:-15.82, ploss:-20.99\n",
      "Batch 6/36, loss:-22.95, ploss:-10.40\n",
      "Batch 7/36, loss:-15.39, ploss:-10.76\n",
      "Batch 8/36, loss:-24.62, ploss:-10.88\n",
      "Batch 9/36, loss:-23.32, ploss:-14.41\n",
      "Batch 10/36, loss:-22.55, ploss:6.1713\n",
      "Batch 11/36, loss:-23.90, ploss:-44.70\n",
      "Batch 12/36, loss:-28.00, ploss:37.602\n",
      "Batch 13/36, loss:-17.30, ploss:-52.66\n",
      "Batch 14/36, loss:-23.57, ploss:24.896\n",
      "Batch 15/36, loss:-29.58, ploss:-35.01\n",
      "Batch 16/36, loss:-28.95, ploss:9.8052\n",
      "Batch 17/36, loss:-22.67, ploss:-33.06\n",
      "Batch 18/36, loss:-24.69, ploss:25.942\n",
      "Batch 19/36, loss:-21.91, ploss:-68.25\n",
      "Batch 20/36, loss:-17.59, ploss:57.769\n",
      "Batch 21/36, loss:-22.36, ploss:-48.65\n",
      "Batch 22/36, loss:-21.93, ploss:18.076\n",
      "Batch 23/36, loss:-29.77, ploss:-37.25\n",
      "Batch 24/36, loss:-34.77, ploss:8.3729\n",
      "Batch 25/36, loss:-25.61, ploss:-32.74\n",
      "Batch 26/36, loss:-36.48, ploss:7.1695\n",
      "Batch 27/36, loss:-30.69, ploss:-35.71\n",
      "Batch 28/36, loss:-29.89, ploss:15.201\n",
      "Batch 29/36, loss:-22.42, ploss:-31.63\n",
      "Batch 30/36, loss:-39.38, ploss:-4.916\n",
      "Batch 31/36, loss:-36.31, ploss:-20.51\n",
      "Batch 32/36, loss:-27.81, ploss:-9.376\n",
      "Batch 33/36, loss:-36.30, ploss:-23.24\n",
      "Batch 34/36, loss:-35.32, ploss:-2.548\n",
      "Batch 35/36, loss:-29.59, ploss:-30.49\n",
      "EPOCH #4\n",
      "Batch 0/36, loss:-32.73, ploss:21.864\n",
      "Batch 1/36, loss:-28.93, ploss:-55.97\n",
      "Batch 2/36, loss:-22.02, ploss:50.791\n",
      "Batch 3/36, loss:-29.20, ploss:-62.50\n",
      "Batch 4/36, loss:-31.60, ploss:46.137\n",
      "Batch 5/36, loss:-34.32, ploss:-53.46\n",
      "Batch 6/36, loss:-36.84, ploss:22.396\n",
      "Batch 7/36, loss:-35.54, ploss:-38.20\n",
      "Batch 8/36, loss:-40.09, ploss:-3.993\n",
      "Batch 9/36, loss:-39.21, ploss:-31.78\n",
      "Batch 10/36, loss:-49.99, ploss:-9.066\n",
      "Batch 11/36, loss:-47.97, ploss:-19.03\n",
      "Batch 12/36, loss:-32.28, ploss:-7.835\n",
      "Batch 13/36, loss:-43.45, ploss:-17.32\n",
      "Batch 14/36, loss:-44.43, ploss:-14.03\n",
      "Batch 15/36, loss:-3.674, ploss:-221.7\n",
      "Batch 16/36, loss:-7.568, ploss:132.54\n",
      "Batch 17/36, loss:-40.19, ploss:-37.06\n",
      "Batch 18/36, loss:-46.89, ploss:-3.739\n",
      "Batch 19/36, loss:-47.34, ploss:-23.83\n",
      "Batch 20/36, loss:-52.45, ploss:-18.83\n",
      "Batch 21/36, loss:-49.10, ploss:-16.05\n",
      "Batch 22/36, loss:-44.41, ploss:-20.64\n",
      "Batch 23/36, loss:-53.71, ploss:-15.63\n",
      "Batch 24/36, loss:-42.42, ploss:-15.93\n",
      "Batch 25/36, loss:-51.15, ploss:-19.11\n",
      "Batch 26/36, loss:-46.19, ploss:-12.62\n",
      "Batch 27/36, loss:-41.40, ploss:-24.40\n",
      "Batch 28/36, loss:-46.40, ploss:-5.021\n",
      "Batch 29/36, loss:-46.08, ploss:-37.51\n",
      "Batch 30/36, loss:-41.51, ploss:20.026\n",
      "Batch 31/36, loss:-46.83, ploss:-55.38\n",
      "Batch 32/36, loss:-43.96, ploss:41.881\n",
      "Batch 33/36, loss:-56.29, ploss:-55.86\n",
      "Batch 34/36, loss:-47.46, ploss:22.183\n",
      "Batch 35/36, loss:-45.72, ploss:-36.71\n",
      "EPOCH #5\n",
      "Batch 0/36, loss:-51.45, ploss:-5.796\n",
      "Batch 1/36, loss:-48.43, ploss:-17.13\n",
      "Batch 2/36, loss:-46.00, ploss:-21.64\n",
      "Batch 3/36, loss:-53.99, ploss:-7.556\n",
      "Batch 4/36, loss:-57.61, ploss:-32.70\n",
      "Batch 5/36, loss:-51.88, ploss:3.3845\n",
      "Batch 6/36, loss:-52.14, ploss:-40.61\n",
      "Batch 7/36, loss:-45.80, ploss:9.8419\n",
      "Batch 8/36, loss:-50.14, ploss:-44.39\n",
      "Batch 9/36, loss:-49.19, ploss:27.103\n",
      "Batch 10/36, loss:-48.17, ploss:-50.72\n",
      "Batch 11/36, loss:-48.83, ploss:22.731\n",
      "Batch 12/36, loss:-57.90, ploss:-34.35\n",
      "Batch 13/36, loss:-50.16, ploss:7.0095\n",
      "Batch 14/36, loss:-56.35, ploss:-41.25\n",
      "Batch 15/36, loss:-50.86, ploss:17.206\n",
      "Batch 16/36, loss:-51.65, ploss:-42.12\n",
      "Batch 17/36, loss:-46.20, ploss:9.0456\n",
      "Batch 18/36, loss:-57.57, ploss:-41.24\n",
      "Batch 19/36, loss:-52.31, ploss:16.077\n",
      "Batch 20/36, loss:-51.45, ploss:-48.50\n",
      "Batch 21/36, loss:-49.66, ploss:22.296\n",
      "Batch 22/36, loss:-51.23, ploss:-40.66\n",
      "Batch 23/36, loss:-60.51, ploss:5.7938\n",
      "Batch 24/36, loss:-58.59, ploss:-34.34\n",
      "Batch 25/36, loss:-60.16, ploss:0.0796\n",
      "Batch 26/36, loss:-57.80, ploss:-33.84\n",
      "Batch 27/36, loss:-54.30, ploss:5.0632\n",
      "Batch 28/36, loss:-56.01, ploss:-21.88\n",
      "Batch 29/36, loss:-59.82, ploss:-13.70\n",
      "Batch 30/36, loss:-60.15, ploss:-23.35\n",
      "Batch 31/36, loss:-55.64, ploss:-3.359\n",
      "Batch 32/36, loss:-66.88, ploss:-34.04\n",
      "Batch 33/36, loss:-54.02, ploss:11.462\n",
      "Batch 34/36, loss:-56.94, ploss:-49.76\n",
      "Batch 35/36, loss:-46.03, ploss:38.360\n",
      "EPOCH #6\n",
      "Batch 0/36, loss:-53.27, ploss:-56.18\n",
      "Batch 1/36, loss:-57.85, ploss:26.810\n",
      "Batch 2/36, loss:-63.26, ploss:-41.73\n",
      "Batch 3/36, loss:-63.53, ploss:1.0549\n",
      "Batch 4/36, loss:-61.71, ploss:-35.67\n",
      "Batch 5/36, loss:-60.98, ploss:2.1472\n",
      "Batch 6/36, loss:-60.05, ploss:-26.73\n",
      "Batch 7/36, loss:-55.59, ploss:-0.033\n",
      "Batch 8/36, loss:-63.00, ploss:-34.75\n",
      "Batch 9/36, loss:-66.22, ploss:1.3539\n",
      "Batch 10/36, loss:-66.42, ploss:-36.33\n",
      "Batch 11/36, loss:-62.59, ploss:10.222\n",
      "Batch 12/36, loss:-62.98, ploss:-33.69\n",
      "Batch 13/36, loss:-59.34, ploss:-4.646\n",
      "Batch 14/36, loss:-55.86, ploss:-28.57\n",
      "Batch 15/36, loss:-63.51, ploss:-3.781\n",
      "Batch 16/36, loss:-68.17, ploss:-19.78\n",
      "Batch 17/36, loss:-68.16, ploss:-18.85\n",
      "Batch 18/36, loss:-68.23, ploss:-21.11\n",
      "Batch 19/36, loss:-63.13, ploss:-6.484\n",
      "Batch 20/36, loss:-67.48, ploss:-31.82\n",
      "Batch 21/36, loss:-63.29, ploss:13.763\n",
      "Batch 22/36, loss:-63.18, ploss:-43.33\n",
      "Batch 23/36, loss:-60.89, ploss:20.699\n",
      "Batch 24/36, loss:-67.11, ploss:-54.68\n",
      "Batch 25/36, loss:-66.46, ploss:26.230\n",
      "Batch 26/36, loss:-73.10, ploss:-41.68\n",
      "Batch 27/36, loss:-61.38, ploss:11.579\n",
      "Batch 28/36, loss:-67.00, ploss:-34.34\n",
      "Batch 29/36, loss:-73.53, ploss:-12.14\n",
      "Batch 30/36, loss:-68.19, ploss:-15.79\n",
      "Batch 31/36, loss:-69.55, ploss:-22.06\n",
      "Batch 32/36, loss:-71.30, ploss:-6.818\n",
      "Batch 33/36, loss:-72.52, ploss:-21.62\n",
      "Batch 34/36, loss:-79.44, ploss:-15.00\n",
      "Batch 35/36, loss:-69.77, ploss:-23.29\n",
      "EPOCH #7\n",
      "Batch 0/36, loss:-68.47, ploss:-6.726\n",
      "Batch 1/36, loss:-76.07, ploss:-25.14\n",
      "Batch 2/36, loss:-65.70, ploss:3.6560\n",
      "Batch 3/36, loss:-67.42, ploss:-43.88\n",
      "Batch 4/36, loss:-66.59, ploss:16.301\n",
      "Batch 5/36, loss:-76.00, ploss:-41.86\n",
      "Batch 6/36, loss:-75.25, ploss:5.4030\n",
      "Batch 7/36, loss:-69.77, ploss:-32.84\n",
      "Batch 8/36, loss:-77.69, ploss:-4.511\n",
      "Batch 9/36, loss:-78.06, ploss:-29.62\n",
      "Batch 10/36, loss:-80.41, ploss:-12.26\n",
      "Batch 11/36, loss:-75.56, ploss:-22.65\n",
      "Batch 12/36, loss:-78.51, ploss:-12.69\n",
      "Batch 13/36, loss:-70.39, ploss:-15.94\n",
      "Batch 14/36, loss:-85.29, ploss:-18.59\n",
      "Batch 15/36, loss:-77.61, ploss:-8.110\n",
      "Batch 16/36, loss:-79.57, ploss:-31.09\n",
      "Batch 17/36, loss:-81.69, ploss:2.8437\n",
      "Batch 18/36, loss:-74.69, ploss:-39.37\n",
      "Batch 19/36, loss:-74.43, ploss:14.259\n",
      "Batch 20/36, loss:-75.29, ploss:-36.41\n",
      "Batch 21/36, loss:-75.61, ploss:3.4105\n",
      "Batch 22/36, loss:-84.68, ploss:-30.31\n",
      "Batch 23/36, loss:-78.45, ploss:-4.813\n",
      "Batch 24/36, loss:-80.55, ploss:-21.98\n",
      "Batch 25/36, loss:-83.01, ploss:-15.46\n",
      "Batch 26/36, loss:-80.47, ploss:-13.20\n",
      "Batch 27/36, loss:-79.83, ploss:-21.75\n",
      "Batch 28/36, loss:-79.80, ploss:-8.735\n",
      "Batch 29/36, loss:-71.98, ploss:-20.16\n",
      "Batch 30/36, loss:-76.24, ploss:-6.286\n",
      "Batch 31/36, loss:-82.96, ploss:-20.97\n",
      "Batch 32/36, loss:-77.39, ploss:-7.622\n",
      "Batch 33/36, loss:-85.76, ploss:-22.02\n",
      "Batch 34/36, loss:-78.83, ploss:-5.799\n",
      "Batch 35/36, loss:-88.73, ploss:-24.94\n",
      "EPOCH #8\n",
      "Batch 0/36, loss:-82.64, ploss:-4.947\n",
      "Batch 1/36, loss:-78.57, ploss:-31.84\n",
      "Batch 2/36, loss:-83.02, ploss:8.1197\n",
      "Batch 3/36, loss:-79.45, ploss:-40.95\n",
      "Batch 4/36, loss:-83.96, ploss:3.6281\n",
      "Batch 5/36, loss:-85.85, ploss:-35.86\n",
      "Batch 6/36, loss:-87.68, ploss:-0.881\n",
      "Batch 7/36, loss:-93.38, ploss:-28.76\n",
      "Batch 8/36, loss:-85.56, ploss:-1.482\n",
      "Batch 9/36, loss:-87.27, ploss:-29.61\n",
      "Batch 10/36, loss:-85.23, ploss:-5.882\n",
      "Batch 11/36, loss:-88.66, ploss:-23.83\n",
      "Batch 12/36, loss:-93.16, ploss:-15.32\n",
      "Batch 13/36, loss:-90.38, ploss:-19.67\n",
      "Batch 14/36, loss:-86.63, ploss:-14.80\n",
      "Batch 15/36, loss:-91.05, ploss:-20.44\n",
      "Batch 16/36, loss:-85.50, ploss:-8.387\n",
      "Batch 17/36, loss:-95.67, ploss:-21.19\n",
      "Batch 18/36, loss:-92.95, ploss:-8.492\n",
      "Batch 19/36, loss:-95.38, ploss:-25.83\n",
      "Batch 20/36, loss:-90.73, ploss:-8.417\n",
      "Batch 21/36, loss:-91.87, ploss:-22.89\n",
      "Batch 22/36, loss:-87.36, ploss:-2.429\n",
      "Batch 23/36, loss:-81.30, ploss:-18.70\n",
      "Batch 24/36, loss:-84.80, ploss:-7.906\n",
      "Batch 25/36, loss:-89.92, ploss:-17.38\n",
      "Batch 26/36, loss:-91.28, ploss:-10.26\n",
      "Batch 27/36, loss:-91.01, ploss:-22.77\n",
      "Batch 28/36, loss:-93.02, ploss:-6.036\n",
      "Batch 29/36, loss:-86.85, ploss:-26.12\n",
      "Batch 30/36, loss:-92.10, ploss:3.3517\n",
      "Batch 31/36, loss:-87.79, ploss:-28.27\n",
      "Batch 32/36, loss:-87.44, ploss:3.6992\n",
      "Batch 33/36, loss:-89.77, ploss:-22.75\n",
      "Batch 34/36, loss:-85.07, ploss:-6.872\n",
      "Batch 35/36, loss:-89.06, ploss:-15.29\n",
      "EPOCH #9\n",
      "Batch 0/36, loss:-98.68, ploss:-23.27\n",
      "Batch 1/36, loss:-93.93, ploss:-9.476\n",
      "Batch 2/36, loss:-96.13, ploss:-24.82\n",
      "Batch 3/36, loss:-93.16, ploss:-4.509\n",
      "Batch 4/36, loss:-96.68, ploss:-28.58\n",
      "Batch 5/36, loss:-97.69, ploss:-3.784\n",
      "Batch 6/36, loss:-94.10, ploss:-24.28\n",
      "Batch 7/36, loss:-95.53, ploss:-8.732\n",
      "Batch 8/36, loss:-97.38, ploss:-20.14\n",
      "Batch 9/36, loss:-90.13, ploss:-8.774\n",
      "Batch 10/36, loss:-94.12, ploss:-22.73\n",
      "Batch 11/36, loss:-93.59, ploss:-0.768\n",
      "Batch 12/36, loss:-101.5, ploss:-28.65\n",
      "Batch 13/36, loss:-100.1, ploss:-7.029\n",
      "Batch 14/36, loss:-91.15, ploss:-21.40\n",
      "Batch 15/36, loss:-99.88, ploss:-9.071\n",
      "Batch 16/36, loss:-103.4, ploss:-18.29\n",
      "Batch 17/36, loss:-100.2, ploss:-21.04\n",
      "Batch 18/36, loss:-100.1, ploss:-9.063\n",
      "Batch 19/36, loss:-98.54, ploss:-23.41\n",
      "Batch 20/36, loss:-94.52, ploss:-2.469\n",
      "Batch 21/36, loss:-88.93, ploss:-24.24\n",
      "Batch 22/36, loss:-98.21, ploss:-5.799\n",
      "Batch 23/36, loss:-96.72, ploss:-20.87\n",
      "Batch 24/36, loss:-94.69, ploss:-4.223\n",
      "Batch 25/36, loss:-103.3, ploss:-21.24\n",
      "Batch 26/36, loss:-93.55, ploss:-10.27\n",
      "Batch 27/36, loss:-104.3, ploss:-14.56\n",
      "Batch 28/36, loss:-93.06, ploss:-12.31\n",
      "Batch 29/36, loss:-105.7, ploss:-18.58\n",
      "Batch 30/36, loss:-99.85, ploss:-11.17\n",
      "Batch 31/36, loss:-96.59, ploss:-13.65\n",
      "Batch 32/36, loss:-99.68, ploss:-10.64\n",
      "Batch 33/36, loss:-90.91, ploss:-7.550\n",
      "Batch 34/36, loss:-99.46, ploss:-16.54\n",
      "Batch 35/36, loss:-101.2, ploss:-9.371\n",
      "EPOCH #10\n",
      "Batch 0/36, loss:-105.1, ploss:-23.66\n",
      "Batch 1/36, loss:-104.2, ploss:-7.112\n",
      "Batch 2/36, loss:-107.6, ploss:-24.44\n",
      "Batch 3/36, loss:-101.0, ploss:-4.116\n",
      "Batch 4/36, loss:-100.5, ploss:-17.92\n",
      "Batch 5/36, loss:-102.7, ploss:-15.62\n",
      "Batch 6/36, loss:-97.38, ploss:-5.562\n",
      "Batch 7/36, loss:-102.9, ploss:-25.02\n",
      "Batch 8/36, loss:-105.3, ploss:-5.323\n",
      "Batch 9/36, loss:-105.8, ploss:-21.68\n",
      "Batch 10/36, loss:-101.5, ploss:-10.68\n",
      "Batch 11/36, loss:-106.3, ploss:-17.73\n",
      "Batch 12/36, loss:-108.1, ploss:-14.43\n",
      "Batch 13/36, loss:-102.7, ploss:-10.93\n",
      "Batch 14/36, loss:-106.7, ploss:-19.61\n",
      "Batch 15/36, loss:-104.4, ploss:-9.518\n",
      "Batch 16/36, loss:-104.7, ploss:-20.26\n",
      "Batch 17/36, loss:-101.2, ploss:-8.059\n",
      "Batch 18/36, loss:-108.9, ploss:-18.00\n",
      "Batch 19/36, loss:-105.4, ploss:-12.18\n",
      "Batch 20/36, loss:-108.8, ploss:-12.78\n",
      "Batch 21/36, loss:-105.0, ploss:-19.13\n",
      "Batch 22/36, loss:-105.0, ploss:-5.735\n",
      "Batch 23/36, loss:-104.8, ploss:-20.83\n",
      "Batch 24/36, loss:-108.8, ploss:-6.476\n",
      "Batch 25/36, loss:-102.4, ploss:-17.38\n",
      "Batch 26/36, loss:-108.4, ploss:-10.07\n",
      "Batch 27/36, loss:-106.6, ploss:-17.39\n",
      "Batch 28/36, loss:-105.8, ploss:-10.05\n",
      "Batch 29/36, loss:-102.3, ploss:-9.346\n",
      "Batch 30/36, loss:-104.5, ploss:-17.46\n",
      "Batch 31/36, loss:-106.2, ploss:-4.201\n",
      "Batch 32/36, loss:-102.0, ploss:-20.85\n",
      "Batch 33/36, loss:-104.4, ploss:-3.876\n",
      "Batch 34/36, loss:-105.9, ploss:-24.35\n",
      "Batch 35/36, loss:-104.4, ploss:2.1186\n",
      "EPOCH #11\n",
      "Batch 0/36, loss:-109.4, ploss:-25.04\n",
      "Batch 1/36, loss:-108.9, ploss:-7.552\n",
      "Batch 2/36, loss:-110.6, ploss:-18.41\n",
      "Batch 3/36, loss:-106.7, ploss:-15.49\n",
      "Batch 4/36, loss:-113.8, ploss:-14.39\n",
      "Batch 5/36, loss:-106.5, ploss:-14.54\n",
      "Batch 6/36, loss:-105.2, ploss:-13.89\n",
      "Batch 7/36, loss:-113.0, ploss:-10.30\n",
      "Batch 8/36, loss:-102.4, ploss:-15.42\n",
      "Batch 9/36, loss:-108.9, ploss:-10.01\n",
      "Batch 10/36, loss:-107.9, ploss:-13.30\n",
      "Batch 11/36, loss:-110.9, ploss:-10.81\n",
      "Batch 12/36, loss:-114.8, ploss:-15.73\n",
      "Batch 13/36, loss:-112.9, ploss:-9.915\n",
      "Batch 14/36, loss:-110.2, ploss:-18.40\n",
      "Batch 15/36, loss:-117.5, ploss:-9.528\n",
      "Batch 16/36, loss:-113.6, ploss:-19.30\n",
      "Batch 17/36, loss:-113.8, ploss:-7.761\n",
      "Batch 18/36, loss:-112.6, ploss:-18.28\n",
      "Batch 19/36, loss:-112.4, ploss:-5.792\n",
      "Batch 20/36, loss:-110.9, ploss:-17.36\n",
      "Batch 21/36, loss:-111.0, ploss:-7.828\n",
      "Batch 22/36, loss:-105.3, ploss:-16.12\n",
      "Batch 23/36, loss:-110.5, ploss:-6.177\n",
      "Batch 24/36, loss:-105.6, ploss:-18.94\n",
      "Batch 25/36, loss:-107.7, ploss:-2.478\n",
      "Batch 26/36, loss:-106.5, ploss:-20.26\n",
      "Batch 27/36, loss:-106.6, ploss:1.0160\n",
      "Batch 28/36, loss:-111.4, ploss:-20.07\n",
      "Batch 29/36, loss:-118.6, ploss:-7.152\n",
      "Batch 30/36, loss:-111.7, ploss:-15.73\n",
      "Batch 31/36, loss:-105.4, ploss:-10.10\n",
      "Batch 32/36, loss:-105.5, ploss:-10.41\n",
      "Batch 33/36, loss:-113.3, ploss:-13.47\n",
      "Batch 34/36, loss:-110.1, ploss:-13.15\n",
      "Batch 35/36, loss:-110.7, ploss:-9.316\n",
      "EPOCH #12\n",
      "Batch 0/36, loss:-112.5, ploss:-15.20\n",
      "Batch 1/36, loss:-118.1, ploss:-16.67\n",
      "Batch 2/36, loss:-117.7, ploss:-17.14\n",
      "Batch 3/36, loss:-118.9, ploss:-12.22\n",
      "Batch 4/36, loss:-115.7, ploss:-21.14\n",
      "Batch 5/36, loss:-116.9, ploss:-13.50\n",
      "Batch 6/36, loss:-116.0, ploss:-18.87\n",
      "Batch 7/36, loss:-118.3, ploss:-9.647\n",
      "Batch 8/36, loss:-117.5, ploss:-18.15\n",
      "Batch 9/36, loss:-119.9, ploss:-10.14\n",
      "Batch 10/36, loss:-113.9, ploss:-17.33\n",
      "Batch 11/36, loss:-114.0, ploss:-10.92\n",
      "Batch 12/36, loss:-115.4, ploss:-18.83\n",
      "Batch 13/36, loss:-114.0, ploss:-11.28\n",
      "Batch 14/36, loss:-108.6, ploss:-21.43\n",
      "Batch 15/36, loss:-110.8, ploss:-5.803\n",
      "Batch 16/36, loss:-114.7, ploss:-18.92\n",
      "Batch 17/36, loss:-111.6, ploss:-6.851\n",
      "Batch 18/36, loss:-118.4, ploss:-17.83\n",
      "Batch 19/36, loss:-115.2, ploss:-9.771\n",
      "Batch 20/36, loss:-113.5, ploss:-16.80\n",
      "Batch 21/36, loss:-117.4, ploss:-9.905\n",
      "Batch 22/36, loss:-118.5, ploss:-14.92\n",
      "Batch 23/36, loss:-116.4, ploss:-9.588\n",
      "Batch 24/36, loss:-120.4, ploss:-15.29\n",
      "Batch 25/36, loss:-123.2, ploss:-10.08\n",
      "Batch 26/36, loss:-113.7, ploss:-20.27\n",
      "Batch 27/36, loss:-118.8, ploss:-4.965\n",
      "Batch 28/36, loss:-111.8, ploss:-19.18\n",
      "Batch 29/36, loss:-114.6, ploss:-4.408\n",
      "Batch 30/36, loss:-113.0, ploss:-20.10\n",
      "Batch 31/36, loss:-115.8, ploss:-3.414\n",
      "Batch 32/36, loss:-113.9, ploss:-20.33\n",
      "Batch 33/36, loss:-118.1, ploss:-4.024\n",
      "Batch 34/36, loss:-116.2, ploss:-18.01\n",
      "Batch 35/36, loss:-117.0, ploss:-6.275\n",
      "EPOCH #13\n",
      "Batch 0/36, loss:-115.6, ploss:-20.11\n",
      "Batch 1/36, loss:-116.0, ploss:-7.290\n",
      "Batch 2/36, loss:-120.1, ploss:-17.66\n",
      "Batch 3/36, loss:-118.6, ploss:-10.43\n",
      "Batch 4/36, loss:-116.1, ploss:-15.48\n",
      "Batch 5/36, loss:-118.2, ploss:-11.61\n",
      "Batch 6/36, loss:-110.5, ploss:-11.87\n",
      "Batch 7/36, loss:-122.8, ploss:-15.87\n",
      "Batch 8/36, loss:-117.3, ploss:-12.60\n",
      "Batch 9/36, loss:-122.4, ploss:-16.41\n",
      "Batch 10/36, loss:-119.9, ploss:-10.44\n",
      "Batch 11/36, loss:-115.0, ploss:-10.58\n",
      "Batch 12/36, loss:-117.6, ploss:-14.13\n",
      "Batch 13/36, loss:-118.4, ploss:-12.14\n",
      "Batch 14/36, loss:-119.5, ploss:-11.98\n",
      "Batch 15/36, loss:-122.7, ploss:-12.06\n",
      "Batch 16/36, loss:-123.0, ploss:-14.12\n",
      "Batch 17/36, loss:-116.5, ploss:-9.688\n",
      "Batch 18/36, loss:-115.7, ploss:-12.98\n",
      "Batch 19/36, loss:-116.9, ploss:-13.72\n",
      "Batch 20/36, loss:-117.4, ploss:-6.406\n",
      "Batch 21/36, loss:-119.3, ploss:-15.44\n",
      "Batch 22/36, loss:-120.4, ploss:-11.15\n",
      "Batch 23/36, loss:-120.7, ploss:-15.97\n",
      "Batch 24/36, loss:-118.1, ploss:-7.109\n",
      "Batch 25/36, loss:-114.6, ploss:-14.51\n",
      "Batch 26/36, loss:-120.6, ploss:-5.728\n",
      "Batch 27/36, loss:-120.0, ploss:-16.46\n",
      "Batch 28/36, loss:-121.8, ploss:-6.857\n",
      "Batch 29/36, loss:-115.4, ploss:-14.04\n",
      "Batch 30/36, loss:-117.9, ploss:-7.471\n",
      "Batch 31/36, loss:-116.8, ploss:-11.71\n",
      "Batch 32/36, loss:-119.2, ploss:-4.551\n",
      "Batch 33/36, loss:-116.2, ploss:-16.24\n",
      "Batch 34/36, loss:-117.9, ploss:-3.472\n",
      "Batch 35/36, loss:-121.3, ploss:-14.15\n",
      "EPOCH #14\n",
      "Batch 0/36, loss:-121.9, ploss:-9.107\n",
      "Batch 1/36, loss:-125.5, ploss:-15.76\n",
      "Batch 2/36, loss:-119.8, ploss:-8.238\n",
      "Batch 3/36, loss:-122.2, ploss:-17.74\n",
      "Batch 4/36, loss:-123.2, ploss:-11.02\n",
      "Batch 5/36, loss:-118.7, ploss:-14.21\n",
      "Batch 6/36, loss:-118.4, ploss:-10.51\n",
      "Batch 7/36, loss:-120.9, ploss:-6.880\n",
      "Batch 8/36, loss:-123.4, ploss:-17.68\n",
      "Batch 9/36, loss:-123.1, ploss:-8.217\n",
      "Batch 10/36, loss:-127.5, ploss:-17.51\n",
      "Batch 11/36, loss:-127.1, ploss:-11.10\n",
      "Batch 12/36, loss:-126.7, ploss:-17.45\n",
      "Batch 13/36, loss:-126.0, ploss:-9.350\n",
      "Batch 14/36, loss:-121.3, ploss:-17.14\n",
      "Batch 15/36, loss:-119.6, ploss:-2.445\n",
      "Batch 16/36, loss:-118.3, ploss:-18.77\n",
      "Batch 17/36, loss:-120.3, ploss:-6.991\n",
      "Batch 18/36, loss:-121.0, ploss:-13.09\n",
      "Batch 19/36, loss:-119.7, ploss:-9.885\n",
      "Batch 20/36, loss:-121.2, ploss:-11.14\n",
      "Batch 21/36, loss:-116.3, ploss:-11.48\n",
      "Batch 22/36, loss:-124.2, ploss:-8.938\n",
      "Batch 23/36, loss:-127.6, ploss:-14.39\n",
      "Batch 24/36, loss:-122.9, ploss:-8.549\n",
      "Batch 25/36, loss:-119.4, ploss:-13.84\n",
      "Batch 26/36, loss:-125.9, ploss:-10.18\n",
      "Batch 27/36, loss:-124.6, ploss:-14.61\n",
      "Batch 28/36, loss:-124.7, ploss:-9.477\n",
      "Batch 29/36, loss:-124.7, ploss:-12.66\n",
      "Batch 30/36, loss:-122.1, ploss:-9.271\n",
      "Batch 31/36, loss:-122.7, ploss:-15.30\n",
      "Batch 32/36, loss:-120.1, ploss:-3.596\n",
      "Batch 33/36, loss:-115.9, ploss:-14.18\n",
      "Batch 34/36, loss:-122.1, ploss:-4.709\n",
      "Batch 35/36, loss:-121.7, ploss:-13.87\n",
      "EPOCH #15\n",
      "Batch 0/36, loss:-128.8, ploss:-11.86\n",
      "Batch 1/36, loss:-129.0, ploss:-16.36\n",
      "Batch 2/36, loss:-124.7, ploss:-11.11\n",
      "Batch 3/36, loss:-125.1, ploss:-12.16\n",
      "Batch 4/36, loss:-125.4, ploss:-8.915\n",
      "Batch 5/36, loss:-120.6, ploss:-16.13\n",
      "Batch 6/36, loss:-126.8, ploss:-7.313\n",
      "Batch 7/36, loss:-127.6, ploss:-17.04\n",
      "Batch 8/36, loss:-129.2, ploss:-9.179\n",
      "Batch 9/36, loss:-126.9, ploss:-14.44\n",
      "Batch 10/36, loss:-128.7, ploss:-11.46\n",
      "Batch 11/36, loss:-126.3, ploss:-12.37\n",
      "Batch 12/36, loss:-127.2, ploss:-10.66\n",
      "Batch 13/36, loss:-127.2, ploss:-16.32\n",
      "Batch 14/36, loss:-124.5, ploss:-6.646\n",
      "Batch 15/36, loss:-121.3, ploss:-14.46\n",
      "Batch 16/36, loss:-123.0, ploss:-5.023\n",
      "Batch 17/36, loss:-126.5, ploss:-15.35\n",
      "Batch 18/36, loss:-125.5, ploss:-7.288\n",
      "Batch 19/36, loss:-125.7, ploss:-16.36\n",
      "Batch 20/36, loss:-123.2, ploss:-3.954\n",
      "Batch 21/36, loss:-121.7, ploss:-10.56\n",
      "Batch 22/36, loss:-124.5, ploss:-10.38\n",
      "Batch 23/36, loss:-122.4, ploss:-10.84\n",
      "Batch 24/36, loss:-123.5, ploss:-13.01\n",
      "Batch 25/36, loss:-124.2, ploss:-8.730\n",
      "Batch 26/36, loss:-125.9, ploss:-12.17\n",
      "Batch 27/36, loss:-129.4, ploss:-9.878\n",
      "Batch 28/36, loss:-128.9, ploss:-11.55\n",
      "Batch 29/36, loss:-127.0, ploss:-12.25\n",
      "Batch 30/36, loss:-121.1, ploss:-8.767\n",
      "Batch 31/36, loss:-124.9, ploss:-11.76\n",
      "Batch 32/36, loss:-119.8, ploss:-8.271\n",
      "Batch 33/36, loss:-125.5, ploss:-12.71\n",
      "Batch 34/36, loss:-124.8, ploss:-10.12\n",
      "Batch 35/36, loss:-125.5, ploss:-13.22\n",
      "EPOCH #16\n",
      "Batch 0/36, loss:-125.4, ploss:-10.36\n",
      "Batch 1/36, loss:-126.1, ploss:-15.00\n",
      "Batch 2/36, loss:-127.5, ploss:-9.421\n",
      "Batch 3/36, loss:-128.6, ploss:-15.34\n",
      "Batch 4/36, loss:-130.3, ploss:-8.072\n",
      "Batch 5/36, loss:-127.8, ploss:-14.80\n",
      "Batch 6/36, loss:-130.4, ploss:-7.153\n",
      "Batch 7/36, loss:-128.4, ploss:-17.44\n",
      "Batch 8/36, loss:-125.3, ploss:-9.820\n",
      "Batch 9/36, loss:-129.4, ploss:-14.53\n",
      "Batch 10/36, loss:-127.0, ploss:-12.20\n",
      "Batch 11/36, loss:-125.3, ploss:-11.74\n",
      "Batch 12/36, loss:-131.6, ploss:-11.60\n",
      "Batch 13/36, loss:-129.6, ploss:-12.57\n",
      "Batch 14/36, loss:-126.6, ploss:-8.833\n",
      "Batch 15/36, loss:-128.9, ploss:-9.848\n",
      "Batch 16/36, loss:-128.3, ploss:-15.91\n",
      "Batch 17/36, loss:-125.8, ploss:-4.095\n",
      "Batch 18/36, loss:-128.5, ploss:-14.76\n",
      "Batch 19/36, loss:-126.7, ploss:-7.580\n",
      "Batch 20/36, loss:-128.1, ploss:-13.55\n",
      "Batch 21/36, loss:-131.0, ploss:-9.459\n",
      "Batch 22/36, loss:-130.1, ploss:-12.70\n",
      "Batch 23/36, loss:-130.5, ploss:-10.55\n",
      "Batch 24/36, loss:-126.8, ploss:-9.111\n",
      "Batch 25/36, loss:-127.4, ploss:-9.227\n",
      "Batch 26/36, loss:-128.8, ploss:-9.919\n",
      "Batch 27/36, loss:-128.3, ploss:-9.654\n",
      "Batch 28/36, loss:-129.5, ploss:-13.19\n",
      "Batch 29/36, loss:-127.9, ploss:-6.983\n",
      "Batch 30/36, loss:-128.7, ploss:-14.96\n",
      "Batch 31/36, loss:-128.2, ploss:-6.785\n",
      "Batch 32/36, loss:-130.0, ploss:-17.18\n",
      "Batch 33/36, loss:-131.9, ploss:-5.810\n",
      "Batch 34/36, loss:-124.7, ploss:-14.67\n",
      "Batch 35/36, loss:-127.1, ploss:-6.688\n",
      "EPOCH #17\n",
      "Batch 0/36, loss:-129.1, ploss:-11.96\n",
      "Batch 1/36, loss:-126.2, ploss:-14.03\n",
      "Batch 2/36, loss:-135.7, ploss:-13.60\n",
      "Batch 3/36, loss:-131.3, ploss:-12.37\n",
      "Batch 4/36, loss:-130.4, ploss:-12.82\n",
      "Batch 5/36, loss:-131.7, ploss:-11.50\n",
      "Batch 6/36, loss:-131.2, ploss:-12.87\n",
      "Batch 7/36, loss:-133.0, ploss:-11.63\n",
      "Batch 8/36, loss:-129.3, ploss:-11.22\n",
      "Batch 9/36, loss:-124.4, ploss:-11.17\n",
      "Batch 10/36, loss:-132.0, ploss:-10.09\n",
      "Batch 11/36, loss:-124.7, ploss:-6.532\n",
      "Batch 12/36, loss:-129.5, ploss:-12.58\n",
      "Batch 13/36, loss:-135.2, ploss:-8.121\n",
      "Batch 14/36, loss:-132.0, ploss:-15.32\n",
      "Batch 15/36, loss:-131.6, ploss:-8.426\n",
      "Batch 16/36, loss:-132.7, ploss:-12.60\n",
      "Batch 17/36, loss:-132.4, ploss:-8.921\n",
      "Batch 18/36, loss:-127.9, ploss:-11.19\n",
      "Batch 19/36, loss:-127.1, ploss:-10.89\n",
      "Batch 20/36, loss:-129.1, ploss:-9.782\n",
      "Batch 21/36, loss:-131.0, ploss:-13.77\n",
      "Batch 22/36, loss:-130.8, ploss:-7.516\n",
      "Batch 23/36, loss:-128.1, ploss:-11.21\n",
      "Batch 24/36, loss:-131.2, ploss:-10.38\n",
      "Batch 25/36, loss:-132.8, ploss:-9.806\n",
      "Batch 26/36, loss:-131.3, ploss:-11.27\n",
      "Batch 27/36, loss:-134.1, ploss:-8.447\n",
      "Batch 28/36, loss:-135.5, ploss:-12.08\n",
      "Batch 29/36, loss:-128.3, ploss:-7.019\n",
      "Batch 30/36, loss:-132.2, ploss:-11.68\n",
      "Batch 31/36, loss:-128.9, ploss:-8.775\n",
      "Batch 32/36, loss:-130.3, ploss:-7.209\n",
      "Batch 33/36, loss:-126.8, ploss:-10.14\n",
      "Batch 34/36, loss:-127.7, ploss:-8.008\n",
      "Batch 35/36, loss:-130.7, ploss:-11.95\n",
      "EPOCH #18\n",
      "Batch 0/36, loss:-130.2, ploss:-12.70\n",
      "Batch 1/36, loss:-130.6, ploss:-10.18\n",
      "Batch 2/36, loss:-131.0, ploss:-15.47\n",
      "Batch 3/36, loss:-134.6, ploss:-9.294\n",
      "Batch 4/36, loss:-132.8, ploss:-16.10\n",
      "Batch 5/36, loss:-132.2, ploss:-5.161\n",
      "Batch 6/36, loss:-130.9, ploss:-16.86\n",
      "Batch 7/36, loss:-131.7, ploss:-6.185\n",
      "Batch 8/36, loss:-131.8, ploss:-15.51\n",
      "Batch 9/36, loss:-136.4, ploss:-8.947\n",
      "Batch 10/36, loss:-134.2, ploss:-14.49\n",
      "Batch 11/36, loss:-133.5, ploss:-9.263\n",
      "Batch 12/36, loss:-131.8, ploss:-13.26\n",
      "Batch 13/36, loss:-132.6, ploss:-8.236\n",
      "Batch 14/36, loss:-133.5, ploss:-12.53\n",
      "Batch 15/36, loss:-133.0, ploss:-10.74\n",
      "Batch 16/36, loss:-137.7, ploss:-11.97\n",
      "Batch 17/36, loss:-134.7, ploss:-9.923\n",
      "Batch 18/36, loss:-134.1, ploss:-11.70\n",
      "Batch 19/36, loss:-132.7, ploss:-9.730\n",
      "Batch 20/36, loss:-136.5, ploss:-11.35\n",
      "Batch 21/36, loss:-133.0, ploss:-7.911\n",
      "Batch 22/36, loss:-133.9, ploss:-11.23\n",
      "Batch 23/36, loss:-134.9, ploss:-8.695\n",
      "Batch 24/36, loss:-131.1, ploss:-12.87\n",
      "Batch 25/36, loss:-134.2, ploss:-8.377\n",
      "Batch 26/36, loss:-136.3, ploss:-13.08\n",
      "Batch 27/36, loss:-132.3, ploss:-9.481\n",
      "Batch 28/36, loss:-133.2, ploss:-11.50\n",
      "Batch 29/36, loss:-134.9, ploss:-11.05\n",
      "Batch 30/36, loss:-131.0, ploss:-9.731\n",
      "Batch 31/36, loss:-137.5, ploss:-7.836\n",
      "Batch 32/36, loss:-132.2, ploss:-10.89\n",
      "Batch 33/36, loss:-132.4, ploss:-7.904\n",
      "Batch 34/36, loss:-128.4, ploss:-10.86\n",
      "Batch 35/36, loss:-133.5, ploss:-6.324\n",
      "EPOCH #19\n",
      "Batch 0/36, loss:-138.5, ploss:-14.91\n",
      "Batch 1/36, loss:-136.0, ploss:-8.503\n",
      "Batch 2/36, loss:-137.4, ploss:-14.48\n",
      "Batch 3/36, loss:-137.6, ploss:-9.612\n",
      "Batch 4/36, loss:-138.8, ploss:-12.44\n",
      "Batch 5/36, loss:-135.1, ploss:-12.26\n",
      "Batch 6/36, loss:-134.7, ploss:-11.09\n",
      "Batch 7/36, loss:-131.5, ploss:-10.56\n",
      "Batch 8/36, loss:-136.9, ploss:-11.52\n",
      "Batch 9/36, loss:-137.2, ploss:-11.43\n",
      "Batch 10/36, loss:-135.6, ploss:-10.89\n",
      "Batch 11/36, loss:-138.5, ploss:-13.00\n",
      "Batch 12/36, loss:-137.8, ploss:-8.886\n",
      "Batch 13/36, loss:-136.6, ploss:-13.63\n",
      "Batch 14/36, loss:-133.6, ploss:-7.523\n",
      "Batch 15/36, loss:-137.6, ploss:-12.31\n",
      "Batch 16/36, loss:-137.9, ploss:-8.324\n",
      "Batch 17/36, loss:-137.5, ploss:-13.88\n",
      "Batch 18/36, loss:-135.0, ploss:-6.510\n",
      "Batch 19/36, loss:-134.8, ploss:-15.84\n",
      "Batch 20/36, loss:-136.1, ploss:-3.661\n",
      "Batch 21/36, loss:-134.4, ploss:-15.25\n",
      "Batch 22/36, loss:-131.2, ploss:-4.992\n",
      "Batch 23/36, loss:-131.8, ploss:-10.96\n",
      "Batch 24/36, loss:-129.4, ploss:-6.251\n",
      "Batch 25/36, loss:-139.1, ploss:-10.65\n",
      "Batch 26/36, loss:-133.7, ploss:-11.28\n",
      "Batch 27/36, loss:-138.3, ploss:-10.99\n",
      "Batch 28/36, loss:-130.1, ploss:-7.140\n",
      "Batch 29/36, loss:-133.9, ploss:-12.47\n",
      "Batch 30/36, loss:-134.9, ploss:-8.961\n",
      "Batch 31/36, loss:-133.3, ploss:-13.45\n",
      "Batch 32/36, loss:-136.4, ploss:-5.481\n",
      "Batch 33/36, loss:-134.5, ploss:-11.59\n",
      "Batch 34/36, loss:-130.8, ploss:-6.308\n",
      "Batch 35/36, loss:-132.5, ploss:-13.60\n",
      "EPOCH #20\n",
      "Batch 0/36, loss:-136.2, ploss:-9.244\n",
      "Batch 1/36, loss:-138.2, ploss:-12.04\n",
      "Batch 2/36, loss:-140.5, ploss:-11.42\n",
      "Batch 3/36, loss:-135.7, ploss:-10.70\n",
      "Batch 4/36, loss:-137.0, ploss:-10.13\n",
      "Batch 5/36, loss:-138.5, ploss:-12.00\n",
      "Batch 6/36, loss:-139.0, ploss:-9.541\n",
      "Batch 7/36, loss:-139.0, ploss:-11.70\n",
      "Batch 8/36, loss:-138.9, ploss:-10.88\n",
      "Batch 9/36, loss:-132.3, ploss:-10.96\n",
      "Batch 10/36, loss:-127.9, ploss:-9.219\n",
      "Batch 11/36, loss:-135.3, ploss:-10.02\n",
      "Batch 12/36, loss:-139.3, ploss:-12.96\n",
      "Batch 13/36, loss:-135.4, ploss:-11.42\n",
      "Batch 14/36, loss:-138.1, ploss:-10.44\n",
      "Batch 15/36, loss:-139.8, ploss:-10.32\n",
      "Batch 16/36, loss:-138.0, ploss:-10.85\n",
      "Batch 17/36, loss:-141.1, ploss:-10.24\n",
      "Batch 18/36, loss:-136.3, ploss:-11.90\n",
      "Batch 19/36, loss:-137.2, ploss:-9.598\n",
      "Batch 20/36, loss:-141.3, ploss:-11.74\n",
      "Batch 21/36, loss:-141.6, ploss:-7.766\n",
      "Batch 22/36, loss:-137.9, ploss:-14.69\n",
      "Batch 23/36, loss:-135.6, ploss:-5.330\n",
      "Batch 24/36, loss:-134.0, ploss:-14.38\n",
      "Batch 25/36, loss:-137.0, ploss:-8.174\n",
      "Batch 26/36, loss:-138.2, ploss:-11.80\n",
      "Batch 27/36, loss:-136.2, ploss:-6.976\n",
      "Batch 28/36, loss:-136.9, ploss:-10.39\n",
      "Batch 29/36, loss:-138.4, ploss:-10.43\n",
      "Batch 30/36, loss:-137.6, ploss:-10.71\n",
      "Batch 31/36, loss:-136.5, ploss:-10.43\n",
      "Batch 32/36, loss:-129.9, ploss:-8.501\n",
      "Batch 33/36, loss:-138.8, ploss:-10.02\n",
      "Batch 34/36, loss:-138.7, ploss:-9.386\n",
      "Batch 35/36, loss:-139.2, ploss:-10.91\n",
      "EPOCH #21\n",
      "Batch 0/36, loss:-142.9, ploss:-12.83\n",
      "Batch 1/36, loss:-144.3, ploss:-10.94\n",
      "Batch 2/36, loss:-141.8, ploss:-10.69\n",
      "Batch 3/36, loss:-143.5, ploss:-12.84\n",
      "Batch 4/36, loss:-138.4, ploss:-10.49\n",
      "Batch 5/36, loss:-137.6, ploss:-11.63\n",
      "Batch 6/36, loss:-134.7, ploss:-7.234\n",
      "Batch 7/36, loss:-136.0, ploss:-11.31\n",
      "Batch 8/36, loss:-139.8, ploss:-6.880\n",
      "Batch 9/36, loss:-138.1, ploss:-11.38\n",
      "Batch 10/36, loss:-141.1, ploss:-10.20\n",
      "Batch 11/36, loss:-142.4, ploss:-8.769\n",
      "Batch 12/36, loss:-139.0, ploss:-11.56\n",
      "Batch 13/36, loss:-136.2, ploss:-7.012\n",
      "Batch 14/36, loss:-140.2, ploss:-13.49\n",
      "Batch 15/36, loss:-135.6, ploss:-6.497\n",
      "Batch 16/36, loss:-141.4, ploss:-12.09\n",
      "Batch 17/36, loss:-139.6, ploss:-8.061\n",
      "Batch 18/36, loss:-140.3, ploss:-14.38\n",
      "Batch 19/36, loss:-139.2, ploss:-10.42\n",
      "Batch 20/36, loss:-136.2, ploss:-8.738\n",
      "Batch 21/36, loss:-133.3, ploss:-9.348\n",
      "Batch 22/36, loss:-137.8, ploss:-9.188\n",
      "Batch 23/36, loss:-139.2, ploss:-9.902\n",
      "Batch 24/36, loss:-137.3, ploss:-12.84\n",
      "Batch 25/36, loss:-140.1, ploss:-9.701\n",
      "Batch 26/36, loss:-141.4, ploss:-11.89\n",
      "Batch 27/36, loss:-138.1, ploss:-7.006\n",
      "Batch 28/36, loss:-137.2, ploss:-9.773\n",
      "Batch 29/36, loss:-141.3, ploss:-9.691\n",
      "Batch 30/36, loss:-135.7, ploss:-9.623\n",
      "Batch 31/36, loss:-139.8, ploss:-11.64\n",
      "Batch 32/36, loss:-141.2, ploss:-8.935\n",
      "Batch 33/36, loss:-138.6, ploss:-11.98\n",
      "Batch 34/36, loss:-139.2, ploss:-7.487\n",
      "Batch 35/36, loss:-139.4, ploss:-12.49\n",
      "EPOCH #22\n",
      "Batch 0/36, loss:-144.3, ploss:-7.269\n",
      "Batch 1/36, loss:-142.4, ploss:-13.51\n",
      "Batch 2/36, loss:-137.1, ploss:-6.310\n",
      "Batch 3/36, loss:-143.4, ploss:-12.98\n",
      "Batch 4/36, loss:-142.8, ploss:-9.930\n",
      "Batch 5/36, loss:-140.9, ploss:-10.43\n",
      "Batch 6/36, loss:-139.9, ploss:-10.78\n",
      "Batch 7/36, loss:-142.6, ploss:-10.37\n",
      "Batch 8/36, loss:-141.2, ploss:-10.56\n",
      "Batch 9/36, loss:-140.6, ploss:-10.33\n",
      "Batch 10/36, loss:-142.2, ploss:-10.26\n",
      "Batch 11/36, loss:-142.3, ploss:-10.61\n",
      "Batch 12/36, loss:-140.7, ploss:-12.20\n",
      "Batch 13/36, loss:-140.3, ploss:-8.259\n",
      "Batch 14/36, loss:-142.5, ploss:-11.49\n",
      "Batch 15/36, loss:-140.8, ploss:-8.927\n",
      "Batch 16/36, loss:-144.7, ploss:-8.772\n",
      "Batch 17/36, loss:-142.7, ploss:-10.91\n",
      "Batch 18/36, loss:-139.0, ploss:-6.853\n",
      "Batch 19/36, loss:-139.8, ploss:-13.73\n",
      "Batch 20/36, loss:-141.0, ploss:-5.528\n",
      "Batch 21/36, loss:-142.3, ploss:-12.87\n",
      "Batch 22/36, loss:-136.5, ploss:-7.853\n",
      "Batch 23/36, loss:-138.8, ploss:-12.28\n",
      "Batch 24/36, loss:-136.4, ploss:-5.667\n",
      "Batch 25/36, loss:-138.9, ploss:-13.44\n",
      "Batch 26/36, loss:-135.9, ploss:-6.652\n",
      "Batch 27/36, loss:-136.8, ploss:-10.28\n",
      "Batch 28/36, loss:-141.0, ploss:-10.68\n",
      "Batch 29/36, loss:-138.9, ploss:-8.187\n",
      "Batch 30/36, loss:-135.4, ploss:-11.56\n",
      "Batch 31/36, loss:-140.8, ploss:-7.240\n",
      "Batch 32/36, loss:-139.7, ploss:-10.75\n",
      "Batch 33/36, loss:-139.9, ploss:-11.16\n",
      "Batch 34/36, loss:-141.1, ploss:-10.28\n",
      "Batch 35/36, loss:-141.3, ploss:-10.68\n",
      "EPOCH #23\n",
      "Batch 0/36, loss:-143.9, ploss:-11.43\n",
      "Batch 1/36, loss:-143.2, ploss:-11.24\n",
      "Batch 2/36, loss:-138.9, ploss:-9.872\n",
      "Batch 3/36, loss:-142.8, ploss:-10.69\n",
      "Batch 4/36, loss:-142.5, ploss:-11.46\n",
      "Batch 5/36, loss:-143.1, ploss:-10.68\n",
      "Batch 6/36, loss:-146.0, ploss:-11.54\n",
      "Batch 7/36, loss:-143.2, ploss:-11.04\n",
      "Batch 8/36, loss:-144.9, ploss:-10.30\n",
      "Batch 9/36, loss:-143.3, ploss:-10.35\n",
      "Batch 10/36, loss:-143.0, ploss:-8.731\n",
      "Batch 11/36, loss:-142.2, ploss:-12.23\n",
      "Batch 12/36, loss:-144.8, ploss:-8.305\n",
      "Batch 13/36, loss:-146.4, ploss:-12.79\n",
      "Batch 14/36, loss:-143.3, ploss:-9.864\n",
      "Batch 15/36, loss:-141.9, ploss:-12.64\n",
      "Batch 16/36, loss:-142.2, ploss:-8.200\n",
      "Batch 17/36, loss:-142.1, ploss:-14.08\n",
      "Batch 18/36, loss:-142.5, ploss:-6.088\n",
      "Batch 19/36, loss:-142.8, ploss:-12.15\n",
      "Batch 20/36, loss:-141.1, ploss:-7.736\n",
      "Batch 21/36, loss:-145.7, ploss:-11.77\n",
      "Batch 22/36, loss:-142.6, ploss:-8.778\n",
      "Batch 23/36, loss:-142.6, ploss:-8.089\n",
      "Batch 24/36, loss:-135.5, ploss:-8.633\n",
      "Batch 25/36, loss:-136.6, ploss:-4.913\n",
      "Batch 26/36, loss:-141.8, ploss:-9.714\n",
      "Batch 27/36, loss:-140.4, ploss:-8.771\n",
      "Batch 28/36, loss:-140.6, ploss:-11.71\n",
      "Batch 29/36, loss:-145.2, ploss:-10.73\n",
      "Batch 30/36, loss:-138.9, ploss:-8.308\n",
      "Batch 31/36, loss:-142.1, ploss:-9.374\n",
      "Batch 32/36, loss:-144.5, ploss:-9.970\n",
      "Batch 33/36, loss:-139.0, ploss:-7.143\n",
      "Batch 34/36, loss:-143.1, ploss:-9.828\n",
      "Batch 35/36, loss:-142.3, ploss:-10.99\n",
      "EPOCH #24\n",
      "Batch 0/36, loss:-141.4, ploss:-12.42\n",
      "Batch 1/36, loss:-143.6, ploss:-8.980\n",
      "Batch 2/36, loss:-143.3, ploss:-12.97\n",
      "Batch 3/36, loss:-144.4, ploss:-8.518\n",
      "Batch 4/36, loss:-146.3, ploss:-13.06\n",
      "Batch 5/36, loss:-145.5, ploss:-8.718\n",
      "Batch 6/36, loss:-144.5, ploss:-13.61\n",
      "Batch 7/36, loss:-142.8, ploss:-9.008\n",
      "Batch 8/36, loss:-143.7, ploss:-13.33\n",
      "Batch 9/36, loss:-144.8, ploss:-7.691\n",
      "Batch 10/36, loss:-148.0, ploss:-11.37\n",
      "Batch 11/36, loss:-141.6, ploss:-11.61\n",
      "Batch 12/36, loss:-143.0, ploss:-11.19\n",
      "Batch 13/36, loss:-141.3, ploss:-10.89\n",
      "Batch 14/36, loss:-144.3, ploss:-9.823\n",
      "Batch 15/36, loss:-145.1, ploss:-9.695\n",
      "Batch 16/36, loss:-144.5, ploss:-10.77\n",
      "Batch 17/36, loss:-144.4, ploss:-10.26\n",
      "Batch 18/36, loss:-147.7, ploss:-10.39\n",
      "Batch 19/36, loss:-144.5, ploss:-11.29\n",
      "Batch 20/36, loss:-147.0, ploss:-8.803\n",
      "Batch 21/36, loss:-146.0, ploss:-11.27\n",
      "Batch 22/36, loss:-143.1, ploss:-8.368\n",
      "Batch 23/36, loss:-142.9, ploss:-10.23\n",
      "Batch 24/36, loss:-142.0, ploss:-8.110\n",
      "Batch 25/36, loss:-137.1, ploss:-9.838\n",
      "Batch 26/36, loss:-141.9, ploss:-8.497\n",
      "Batch 27/36, loss:-143.6, ploss:-10.57\n",
      "Batch 28/36, loss:-141.3, ploss:-8.656\n",
      "Batch 29/36, loss:-142.9, ploss:-10.88\n",
      "Batch 30/36, loss:-144.5, ploss:-8.272\n",
      "Batch 31/36, loss:-143.4, ploss:-9.221\n",
      "Batch 32/36, loss:-140.2, ploss:-7.466\n",
      "Batch 33/36, loss:-142.3, ploss:-7.085\n",
      "Batch 34/36, loss:-142.4, ploss:-11.34\n",
      "Batch 35/36, loss:-144.9, ploss:-8.300\n",
      "EPOCH #25\n",
      "Batch 0/36, loss:-144.9, ploss:-12.60\n",
      "Batch 1/36, loss:-144.2, ploss:-9.577\n",
      "Batch 2/36, loss:-144.5, ploss:-14.26\n",
      "Batch 3/36, loss:-145.3, ploss:-6.096\n",
      "Batch 4/36, loss:-144.9, ploss:-13.47\n",
      "Batch 5/36, loss:-141.8, ploss:-6.996\n",
      "Batch 6/36, loss:-144.2, ploss:-11.37\n",
      "Batch 7/36, loss:-141.4, ploss:-7.319\n",
      "Batch 8/36, loss:-147.1, ploss:-11.84\n",
      "Batch 9/36, loss:-145.1, ploss:-11.30\n",
      "Batch 10/36, loss:-144.5, ploss:-10.27\n",
      "Batch 11/36, loss:-145.5, ploss:-11.26\n",
      "Batch 12/36, loss:-148.0, ploss:-10.78\n",
      "Batch 13/36, loss:-148.3, ploss:-11.31\n",
      "Batch 14/36, loss:-149.7, ploss:-10.15\n",
      "Batch 15/36, loss:-146.5, ploss:-8.688\n",
      "Batch 16/36, loss:-146.7, ploss:-11.49\n",
      "Batch 17/36, loss:-144.5, ploss:-9.248\n",
      "Batch 18/36, loss:-144.4, ploss:-10.37\n",
      "Batch 19/36, loss:-148.4, ploss:-8.135\n",
      "Batch 20/36, loss:-145.3, ploss:-9.854\n",
      "Batch 21/36, loss:-141.4, ploss:-7.086\n",
      "Batch 22/36, loss:-144.3, ploss:-12.63\n",
      "Batch 23/36, loss:-145.4, ploss:-7.368\n",
      "Batch 24/36, loss:-145.0, ploss:-11.63\n",
      "Batch 25/36, loss:-143.9, ploss:-5.367\n",
      "Batch 26/36, loss:-143.8, ploss:-10.61\n",
      "Batch 27/36, loss:-144.8, ploss:-7.339\n",
      "Batch 28/36, loss:-143.5, ploss:-10.32\n",
      "Batch 29/36, loss:-147.0, ploss:-7.879\n",
      "Batch 30/36, loss:-141.4, ploss:-8.790\n",
      "Batch 31/36, loss:-143.7, ploss:-9.138\n",
      "Batch 32/36, loss:-144.9, ploss:-10.21\n",
      "Batch 33/36, loss:-145.3, ploss:-8.358\n",
      "Batch 34/36, loss:-143.5, ploss:-11.96\n",
      "Batch 35/36, loss:-144.3, ploss:-6.338\n",
      "EPOCH #26\n",
      "Batch 0/36, loss:-145.5, ploss:-12.96\n",
      "Batch 1/36, loss:-148.4, ploss:-7.453\n",
      "Batch 2/36, loss:-147.2, ploss:-12.43\n",
      "Batch 3/36, loss:-147.4, ploss:-10.38\n",
      "Batch 4/36, loss:-146.9, ploss:-11.94\n",
      "Batch 5/36, loss:-146.9, ploss:-8.918\n",
      "Batch 6/36, loss:-146.9, ploss:-11.16\n",
      "Batch 7/36, loss:-149.1, ploss:-9.377\n",
      "Batch 8/36, loss:-151.9, ploss:-10.55\n",
      "Batch 9/36, loss:-145.5, ploss:-10.45\n",
      "Batch 10/36, loss:-148.7, ploss:-8.677\n",
      "Batch 11/36, loss:-143.8, ploss:-9.638\n",
      "Batch 12/36, loss:-139.8, ploss:-6.224\n",
      "Batch 13/36, loss:-147.2, ploss:-10.82\n",
      "Batch 14/36, loss:-149.2, ploss:-8.203\n",
      "Batch 15/36, loss:-147.0, ploss:-12.27\n",
      "Batch 16/36, loss:-148.0, ploss:-7.304\n",
      "Batch 17/36, loss:-146.8, ploss:-10.46\n",
      "Batch 18/36, loss:-142.7, ploss:-10.16\n",
      "Batch 19/36, loss:-145.6, ploss:-7.868\n",
      "Batch 20/36, loss:-144.8, ploss:-12.09\n",
      "Batch 21/36, loss:-141.2, ploss:-3.709\n",
      "Batch 22/36, loss:-144.4, ploss:-12.69\n",
      "Batch 23/36, loss:-145.3, ploss:-6.169\n",
      "Batch 24/36, loss:-144.9, ploss:-13.42\n",
      "Batch 25/36, loss:-144.4, ploss:-6.199\n",
      "Batch 26/36, loss:-148.4, ploss:-11.76\n",
      "Batch 27/36, loss:-145.7, ploss:-7.465\n",
      "Batch 28/36, loss:-144.9, ploss:-10.74\n",
      "Batch 29/36, loss:-148.8, ploss:-9.743\n",
      "Batch 30/36, loss:-147.2, ploss:-9.190\n",
      "Batch 31/36, loss:-147.9, ploss:-10.08\n",
      "Batch 32/36, loss:-146.0, ploss:-8.540\n",
      "Batch 33/36, loss:-144.9, ploss:-8.580\n",
      "Batch 34/36, loss:-143.8, ploss:-9.267\n",
      "Batch 35/36, loss:-145.2, ploss:-8.941\n",
      "EPOCH #27\n",
      "Batch 0/36, loss:-149.1, ploss:-10.69\n",
      "Batch 1/36, loss:-146.0, ploss:-9.379\n",
      "Batch 2/36, loss:-145.9, ploss:-8.999\n",
      "Batch 3/36, loss:-146.5, ploss:-8.189\n",
      "Batch 4/36, loss:-147.8, ploss:-9.048\n",
      "Batch 5/36, loss:-148.7, ploss:-11.42\n",
      "Batch 6/36, loss:-148.3, ploss:-10.15\n",
      "Batch 7/36, loss:-149.5, ploss:-9.867\n",
      "Batch 8/36, loss:-152.5, ploss:-9.910\n",
      "Batch 9/36, loss:-150.3, ploss:-8.665\n",
      "Batch 10/36, loss:-146.2, ploss:-9.884\n",
      "Batch 11/36, loss:-149.1, ploss:-8.909\n",
      "Batch 12/36, loss:-145.7, ploss:-11.08\n",
      "Batch 13/36, loss:-143.0, ploss:-5.371\n",
      "Batch 14/36, loss:-142.4, ploss:-12.36\n",
      "Batch 15/36, loss:-144.6, ploss:-3.968\n",
      "Batch 16/36, loss:-145.2, ploss:-10.96\n",
      "Batch 17/36, loss:-149.4, ploss:-8.107\n",
      "Batch 18/36, loss:-147.5, ploss:-9.967\n",
      "Batch 19/36, loss:-149.5, ploss:-9.843\n",
      "Batch 20/36, loss:-145.8, ploss:-10.23\n",
      "Batch 21/36, loss:-147.3, ploss:-8.858\n",
      "Batch 22/36, loss:-146.6, ploss:-10.48\n",
      "Batch 23/36, loss:-150.4, ploss:-10.08\n",
      "Batch 24/36, loss:-145.4, ploss:-7.772\n",
      "Batch 25/36, loss:-148.5, ploss:-10.87\n",
      "Batch 26/36, loss:-144.8, ploss:-8.596\n",
      "Batch 27/36, loss:-145.4, ploss:-9.060\n",
      "Batch 28/36, loss:-146.6, ploss:-9.220\n",
      "Batch 29/36, loss:-146.6, ploss:-8.097\n",
      "Batch 30/36, loss:-143.0, ploss:-9.310\n",
      "Batch 31/36, loss:-149.8, ploss:-7.756\n",
      "Batch 32/36, loss:-147.4, ploss:-8.895\n",
      "Batch 33/36, loss:-145.7, ploss:-10.53\n",
      "Batch 34/36, loss:-147.1, ploss:-9.352\n",
      "Batch 35/36, loss:-143.6, ploss:-8.747\n",
      "EPOCH #28\n",
      "Batch 0/36, loss:-144.2, ploss:-10.56\n",
      "Batch 1/36, loss:-147.9, ploss:-9.263\n",
      "Batch 2/36, loss:-148.9, ploss:-11.88\n",
      "Batch 3/36, loss:-148.2, ploss:-9.127\n",
      "Batch 4/36, loss:-148.0, ploss:-8.817\n",
      "Batch 5/36, loss:-151.3, ploss:-8.914\n",
      "Batch 6/36, loss:-150.5, ploss:-8.616\n",
      "Batch 7/36, loss:-152.7, ploss:-10.73\n",
      "Batch 8/36, loss:-151.7, ploss:-9.345\n",
      "Batch 9/36, loss:-149.6, ploss:-11.08\n",
      "Batch 10/36, loss:-149.6, ploss:-7.466\n",
      "Batch 11/36, loss:-148.2, ploss:-10.51\n",
      "Batch 12/36, loss:-149.7, ploss:-8.649\n",
      "Batch 13/36, loss:-149.7, ploss:-8.806\n",
      "Batch 14/36, loss:-147.9, ploss:-9.411\n",
      "Batch 15/36, loss:-148.5, ploss:-8.746\n",
      "Batch 16/36, loss:-148.3, ploss:-9.535\n",
      "Batch 17/36, loss:-150.4, ploss:-11.15\n",
      "Batch 18/36, loss:-151.5, ploss:-8.909\n",
      "Batch 19/36, loss:-151.6, ploss:-10.38\n",
      "Batch 20/36, loss:-146.3, ploss:-8.279\n",
      "Batch 21/36, loss:-147.4, ploss:-9.091\n",
      "Batch 22/36, loss:-144.7, ploss:-7.221\n",
      "Batch 23/36, loss:-148.9, ploss:-9.089\n",
      "Batch 24/36, loss:-146.8, ploss:-7.210\n",
      "Batch 25/36, loss:-146.2, ploss:-9.699\n",
      "Batch 26/36, loss:-145.4, ploss:-8.962\n",
      "Batch 27/36, loss:-147.0, ploss:-8.966\n",
      "Batch 28/36, loss:-148.6, ploss:-7.602\n",
      "Batch 29/36, loss:-147.9, ploss:-9.734\n",
      "Batch 30/36, loss:-146.7, ploss:-9.875\n",
      "Batch 31/36, loss:-147.1, ploss:-10.31\n",
      "Batch 32/36, loss:-148.0, ploss:-7.648\n",
      "Batch 33/36, loss:-147.0, ploss:-9.368\n",
      "Batch 34/36, loss:-148.2, ploss:-8.744\n",
      "Batch 35/36, loss:-147.6, ploss:-9.097\n",
      "EPOCH #29\n",
      "Batch 0/36, loss:-153.0, ploss:-8.377\n",
      "Batch 1/36, loss:-148.3, ploss:-9.217\n",
      "Batch 2/36, loss:-152.3, ploss:-10.52\n",
      "Batch 3/36, loss:-150.0, ploss:-8.149\n",
      "Batch 4/36, loss:-149.5, ploss:-11.62\n",
      "Batch 5/36, loss:-150.7, ploss:-9.386\n",
      "Batch 6/36, loss:-153.0, ploss:-11.52\n",
      "Batch 7/36, loss:-149.2, ploss:-8.525\n",
      "Batch 8/36, loss:-149.2, ploss:-9.465\n",
      "Batch 9/36, loss:-148.4, ploss:-9.401\n",
      "Batch 10/36, loss:-148.8, ploss:-9.016\n",
      "Batch 11/36, loss:-151.2, ploss:-8.366\n",
      "Batch 12/36, loss:-149.7, ploss:-8.448\n",
      "Batch 13/36, loss:-149.4, ploss:-10.54\n",
      "Batch 14/36, loss:-151.8, ploss:-8.740\n",
      "Batch 15/36, loss:-150.9, ploss:-9.613\n",
      "Batch 16/36, loss:-152.1, ploss:-8.213\n",
      "Batch 17/36, loss:-150.8, ploss:-11.17\n",
      "Batch 18/36, loss:-149.3, ploss:-6.484\n",
      "Batch 19/36, loss:-148.4, ploss:-10.21\n",
      "Batch 20/36, loss:-147.1, ploss:-6.568\n",
      "Batch 21/36, loss:-145.4, ploss:-12.06\n",
      "Batch 22/36, loss:-149.0, ploss:-5.473\n",
      "Batch 23/36, loss:-146.7, ploss:-12.56\n",
      "Batch 24/36, loss:-149.4, ploss:-6.951\n",
      "Batch 25/36, loss:-145.8, ploss:-11.24\n",
      "Batch 26/36, loss:-151.7, ploss:-8.847\n",
      "Batch 27/36, loss:-148.4, ploss:-9.812\n",
      "Batch 28/36, loss:-151.7, ploss:-8.972\n",
      "Batch 29/36, loss:-150.6, ploss:-10.22\n",
      "Batch 30/36, loss:-149.5, ploss:-8.529\n",
      "Batch 31/36, loss:-149.5, ploss:-8.704\n",
      "Batch 32/36, loss:-150.1, ploss:-9.575\n",
      "Batch 33/36, loss:-146.3, ploss:-8.276\n",
      "Batch 34/36, loss:-146.8, ploss:-8.595\n",
      "Batch 35/36, loss:-148.1, ploss:-9.130\n"
     ]
    }
   ],
   "source": [
    "print(\"Training network ...\")\n",
    "num_batches_train = int(np.ceil(len(all_audio) / batch_size))\n",
    "split_ratio = 0.8*batch_size\n",
    "\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(\"EPOCH #\"+str(epoch))\n",
    "    tlosses = []\n",
    "    validation_losses = []\n",
    "    vlosses = []\n",
    "    plosses = []\n",
    "    probabilities = []\n",
    "    \n",
    "    training_data=zip(all_audio,all_phn)\n",
    "    np.random.shuffle(training_data)\n",
    "    audio, phonemes = zip(*training_data)\n",
    "    \n",
    "    for batch in range(num_batches_train):\n",
    "        \n",
    "        batch_slice = slice(batch_size * batch, batch_size * (batch + 1))\n",
    "        \n",
    "        xi = audio[batch_slice]\n",
    "        yi = phonemes[batch_slice]\n",
    "        \n",
    "        if batch < split_ratio:\n",
    "            loss, ploss, probs = train(xi,yi)\n",
    "            tlosses.append(loss)\n",
    "            plosses.append(ploss)\n",
    "        else:\n",
    "            loss, probs = validate(xi,yi)\n",
    "            y_pred = np.argmax(probs, axis=-1)\n",
    "            vlosses.append(loss)\n",
    "            probabilities.append(probs)    \n",
    "            \n",
    "        print(\"Batch {0}/{1}, loss:{2:.6}, ploss:{3:.6}\".format(batch,num_batches_train,loss,ploss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Alignment Test using Validation Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network output: \n",
      "\n",
      "_h#_q_ix__tcl_t_ss_ix_____l___iy___gcl_g_ih_l__tcl_t__ax__pcl__p_ow____s__tcl_t_ey__dx__ix_tcltcl__ch___eh_kcl_k_h#__________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "actual output: \n",
      "\n",
      "_h#_q_ix_tcl_t_s_ix_l_iy_gcl_g_ih_l_tcl_t_ax_pcl_p_ow_s_tcl_d_ey_dx_ix_tcl_ch_eh_kcl_k_h#_________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "np.random.shuffle(training_data)\n",
    "audio, phonemes = zip(*training_data)\n",
    "batch_slice = slice(batch_size * batch, batch_size * (batch + 1))\n",
    "xi= audio[batch_slice]\n",
    "yi=phonemes[batch_slice]\n",
    "\n",
    "\n",
    "h5=h5py.File('timit_files/phoneme_list.h5','r')\n",
    "phn_list=h5['list_phn'][:]\n",
    "h5.close()\n",
    "\n",
    "probs=predict(xi)\n",
    "y_pred=np.argmax(probs,axis=-1)\n",
    "y_pred=y_pred[9]\n",
    "\n",
    "phn_str=\"\"\n",
    "label_str=''\n",
    "\n",
    "for i in range(len(y_pred)):\n",
    "    phn_str+=str(phn_list[y_pred[i]])\n",
    "\n",
    "print 'network output: \\n'\n",
    "print phn_str\n",
    "\n",
    "labeled=yi[9]\n",
    "for i in range(len(labeled)):\n",
    "    label_str+=str(phn_list[labeled[i]])\n",
    "print 'actual output: \\n'\n",
    "print label_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_frame_size=0\n",
    "audio_names=[]\n",
    "\n",
    "\n",
    "with h5py.File('timit_files/test_audio.h5', 'r') as h5:\n",
    "    with open('timit_files/test_audio_key.txt','r') as f:\n",
    "        for line in f:\n",
    "            line=line.rstrip()\n",
    "            audio_names.append(line)\n",
    "            cur=h5[line].shape[1]\n",
    "            #print cur\n",
    "            if cur>max_frame_size:\n",
    "                max_frame_size=cur\n",
    "number_of_audio_files=len(audio_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1680"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_audio_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#transposing the data and creating a 3d tensor\n",
    "test_all_audio=np.zeros((number_of_audio_files,327,55))\n",
    "file_ind=0\n",
    "with open('timit_files/test_audio_key.txt','r') as f:\n",
    "    for line in f:\n",
    "        line=line.rstrip()\n",
    "        with h5py.File('timit_files/test_audio_zero_padded.h5', 'r') as h5:\n",
    "            zero_padded_audio=np.transpose(h5[line][:])\n",
    "            for i in range(zero_padded_audio.shape[0]):\n",
    "                for j in range(zero_padded_audio.shape[1]):\n",
    "                    test_all_audio[file_ind][i][j]=zero_padded_audio[i][j]\n",
    "            file_ind+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_all_phn=np.zeros((number_of_audio_files,147))\n",
    "file_ind=0\n",
    "with open('timit_files/test_audio_key.txt','r') as f:\n",
    "    for line in f:\n",
    "        line=line.rstrip()\n",
    "        with h5py.File('timit_files/test_phoneme_list_encode_space_padded.h5', 'r') as h5:\n",
    "            blank_padded_phn=h5[line][:]\n",
    "            for i in range(blank_padded_phn.shape[0]):\n",
    "                test_all_phn[file_ind][i]=blank_padded_phn[i]\n",
    "            file_ind+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#combining audio signals and labels as one\n",
    "test_all_audio=all_audio.astype(np.float32)\n",
    "test_all_phn=all_phn.astype(np.int32)\n",
    "testing_data=zip(all_audio,all_phn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Output using Testing Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network output: \n",
      "\n",
      "_h#__y_ux__kcl_k_uh__dcl__b__er___n_dcl_d__aw__n__dh__ax_s___hh__ow_l___m_n__aw___tcl_________s_____ay___dcl_w_ax_dh__ax___f___ay_____axr__dh__ae___tcl_t_s____ay___s__h#________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "actual output: \n",
      "\n",
      "_h#_y_ux_kcl_k_uh_dcl_b_er_n_dcl_d_aw_n_dh_ax_s_hh_ow_l_m_aw_n_tcl_en_s_ay_dcl_w_ax_dh_ax_f_ay_axr_dh_ae_tcl_t_s_ay_z_h#_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "np.random.shuffle(testing_data)\n",
    "audio, phonemes = zip(*testing_data)\n",
    "batch_slice = slice(batch_size * batch, batch_size * (batch + 1))\n",
    "xi= audio[batch_slice]\n",
    "yi=phonemes[batch_slice]\n",
    "\n",
    "\n",
    "h5=h5py.File('timit_files/phoneme_list.h5','r')\n",
    "phn_list=h5['list_phn'][:]\n",
    "h5.close()\n",
    "\n",
    "probs=predict(xi)\n",
    "y_pred=np.argmax(probs,axis=-1)\n",
    "y_pred=y_pred[11]\n",
    "\n",
    "phn_str=\"\"\n",
    "label_str=''\n",
    "\n",
    "for i in range(len(y_pred)):\n",
    "    phn_str+=str(phn_list[y_pred[i]])\n",
    "\n",
    "print 'network output: \\n'\n",
    "print phn_str\n",
    "\n",
    "labeled=yi[11]\n",
    "for i in range(len(labeled)):\n",
    "    label_str+=str(phn_list[labeled[i]])\n",
    "print 'actual output: \\n'\n",
    "print label_str"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
